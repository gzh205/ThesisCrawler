# ThesisCrawler
一个简易的论文爬虫
## 功能
能够自动根据预先设置的搜索关键字爬取网页，并将其存入数据库中。
## 目前遇到的问题
~~~由于没有ip代理池，很多站点会将爬取行为视作DDOS攻击，导致服务器拒绝连接。~~~
无法准确地获知爬虫结束的条件
## 程序运行原理
"爬虫线程池"中的工作线程首先从"连接池"中获取WebCLient对象用户创建HTTP连接，然后使用WebClient对象打开指定的web页面，读取并分析页面，随后将页面中的有效链接封装成Page对象并添加进"爬虫线程池"中，等待其他工作线程打开该页面。对于需要存入数据库的数据，工作线程会将数据封装成一个ThesisData对象并将其插入"数据库存储线程池"的队列中。